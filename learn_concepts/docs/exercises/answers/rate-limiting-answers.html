<!DOCTYPE html>
<html lang="en" class="scroll-smooth">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Rate Limiting Answers</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700;900&display=swap" rel="stylesheet">
    <script src="https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.min.js"></script>
    <style>
        body {
            font-family: 'Inter', sans-serif;
            background-color: #F0F4F8;
            color: #1E293B;
        }
        .gradient-text {
            background: linear-gradient(90deg, #58508d, #bc5090);
            -webkit-background-clip: text;
            -webkit-text-fill-color: transparent;
        }
        .content {
            background-color: white;
            border-radius: 0.75rem;
            padding: 2rem;
            box-shadow: 0 10px 15px -3px rgb(0 0 0 / 0.05), 0 4px 6px -4px rgb(0 0 0 / 0.05);
            margin-top: 2rem;
        }
        .content h1 {
            font-size: 2.5rem;
            font-weight: 900;
            margin-bottom: 1rem;
            color: #1E293B;
        }
        .content h2 {
            font-size: 2rem;
            font-weight: 700;
            margin-top: 2rem;
            margin-bottom: 1rem;
            color: #1E293B;
            border-bottom: 2px solid #E5E7EB;
            padding-bottom: 0.5rem;
        }
        .content h3 {
            font-size: 1.5rem;
            font-weight: 600;
            margin-top: 1.5rem;
            margin-bottom: 0.75rem;
            color: #1E293B;
        }
        .content h4 {
            font-size: 1.25rem;
            font-weight: 600;
            margin-top: 1rem;
            margin-bottom: 0.5rem;
            color: #1E293B;
        }
        .content p {
            margin-bottom: 1rem;
            line-height: 1.7;
        }
        .content ul, .content ol {
            margin-bottom: 1rem;
            padding-left: 2rem;
        }
        .content li {
            margin-bottom: 0.5rem;
            line-height: 1.6;
        }
        .content code {
            background-color: #F3F4F6;
            padding: 0.2rem 0.4rem;
            border-radius: 0.25rem;
            font-family: 'Courier New', monospace;
            font-size: 0.9em;
        }
        .content pre {
            background-color: #1E293B;
            color: #F0F4F8;
            padding: 1rem;
            border-radius: 0.5rem;
            overflow-x: auto;
            margin-bottom: 1rem;
        }
        .content pre code {
            background-color: transparent;
            padding: 0;
            color: inherit;
        }
        .content blockquote {
            border-left: 4px solid #58508d;
            padding-left: 1rem;
            margin-left: 0;
            margin-bottom: 1rem;
            color: #4B5563;
            font-style: italic;
        }
        .content table {
            width: 100%;
            border-collapse: collapse;
            margin-bottom: 1rem;
        }
        .content th {
            background-color: #F3F4F6;
            padding: 0.75rem;
            text-align: left;
            font-weight: 600;
            border: 1px solid #E5E7EB;
        }
        .content td {
            padding: 0.75rem;
            border: 1px solid #E5E7EB;
        }
        .content tr:nth-child(even) {
            background-color: #F9FAFB;
        }
        .content a {
            color: #58508d;
            text-decoration: underline;
        }
        .content a:hover {
            color: #bc5090;
        }
        .content hr {
            border: none;
            border-top: 2px solid #E5E7EB;
            margin: 2rem 0;
        }
        .mermaid {
            margin: 2rem 0;
            text-align: center;
            background-color: white;
            padding: 1rem;
            border-radius: 0.5rem;
        }
        .sidebar {
            position: fixed;
            top: 80px;
            left: 0;
            height: calc(100vh - 80px);
            width: 280px;
            background-color: white;
            border-right: 1px solid #E5E7EB;
            overflow-y: auto;
            transition: transform 0.3s ease;
            z-index: 40;
            box-shadow: 2px 0 4px rgba(0, 0, 0, 0.05);
        }
        .sidebar.collapsed {
            transform: translateX(-100%);
        }
        .sidebar-toggle {
            position: fixed;
            top: 90px;
            left: 20px;
            z-index: 50;
            background-color: white;
            border: 1px solid #E5E7EB;
            border-radius: 0.5rem;
            padding: 0.5rem;
            cursor: pointer;
            box-shadow: 0 2px 4px rgba(0, 0, 0, 0.1);
            display: none;
        }
        .sidebar-toggle:hover {
            background-color: #F3F4F6;
        }
        .sidebar-content {
            padding: 1.5rem;
        }
        .sidebar-title {
            font-size: 1.125rem;
            font-weight: 700;
            color: #1E293B;
            margin-bottom: 1rem;
            padding-bottom: 0.5rem;
            border-bottom: 2px solid #E5E7EB;
        }
        .sidebar-nav {
            list-style: none;
            padding: 0;
            margin: 0;
        }
        .sidebar-nav li {
            margin-bottom: 0.5rem;
        }
        .sidebar-nav a {
            display: block;
            padding: 0.5rem 0.75rem;
            color: #4B5563;
            text-decoration: none;
            border-radius: 0.375rem;
            transition: all 0.2s;
            font-size: 0.875rem;
        }
        .sidebar-nav a:hover {
            background-color: #F3F4F6;
            color: #58508d;
        }
        .sidebar-nav a.active {
            background-color: #EEF2FF;
            color: #58508d;
            font-weight: 600;
        }
        .sidebar-nav .level-1 {
            padding-left: 0.75rem;
            font-weight: 600;
            color: #1E293B;
        }
        .sidebar-nav .level-2 {
            padding-left: 1.5rem;
            color: #4B5563;
        }
        .sidebar-nav .level-3 {
            padding-left: 2.25rem;
            color: #6B7280;
            font-size: 0.8125rem;
        }
        .sidebar-nav .level-4 {
            padding-left: 3rem;
            color: #9CA3AF;
            font-size: 0.75rem;
        }
        .main-content {
            margin-left: 280px;
            transition: margin-left 0.3s ease;
        }
        .main-content.no-sidebar {
            margin-left: 0;
        }
        @media (max-width: 1024px) {
            .sidebar {
                transform: translateX(-100%);
            }
            .sidebar.expanded {
                transform: translateX(0);
            }
            .sidebar-toggle {
                display: block;
            }
            .main-content {
                margin-left: 0;
            }
        }
    </style>
</head>
<body class="antialiased">
    <header class="bg-white sticky top-0 z-50 shadow-md">
        <nav class="container mx-auto px-4 sm:px-6 py-4 flex justify-between items-center">
            <div class="text-xl sm:text-2xl font-bold text-gray-800">
                <a href="../../../index.html" class="flex items-center">
                    <svg class="w-6 h-6 mr-2" fill="currentColor" viewBox="0 0 20 20" xmlns="http://www.w3.org/2000/svg"><path d="M10.707 2.293a1 1 0 00-1.414 0l-7 7a1 1 0 001.414 1.414L4 10.414V17a1 1 0 001 1h2a1 1 0 001-1v-2a1 1 0 011-1h2a1 1 0 011 1v2a1 1 0 001 1h2a1 1 0 001-1v-6.586l.293.293a1 1 0 001.414-1.414l-7-7z"></path></svg>
                    <span class="gradient-text">Data Engineering Concepts</span>
                </a>
            </div>
            <ul class="flex space-x-4 sm:space-x-6 text-gray-600 font-medium text-sm sm:text-base">
                <li><a href="../../../case_studies.html" class="hover:text-[#bc5090] font-semibold">Case Studies</a></li>
                <li><a href="../../../aboutme.html" class="hover:text-[#bc5090] font-semibold">About Me</a></li>
            </ul>
        </nav>
    </header>
        <button class="sidebar-toggle" id="sidebarToggle" aria-label="Toggle sidebar">
        <svg class="w-5 h-5" fill="none" stroke="currentColor" viewBox="0 0 24 24">
            <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M4 6h16M4 12h16M4 18h16"></path>
        </svg>
    </button>
        <aside class="sidebar" id="sidebar">
        <div class="sidebar-content">
            <div class="sidebar-title">Table of Contents</div>
            <ul class="sidebar-nav">
                <li><a href="#answer-key-rate-limiter-implementations" class="level-1">Answer Key: Rate Limiter Implementations</a></li>
                <li><a href="#exercise-1-implement-token-bucket" class="level-2">Exercise 1: Implement Token Bucket</a></li>
                <li><a href="#answer" class="level-3">Answer</a></li>
                <li><a href="#implementation" class="level-3">Implementation</a></li>
                <li><a href="#edge-cases" class="level-3">Edge Cases</a></li>
                <li><a href="#improved-implementation" class="level-3">Improved Implementation</a></li>
                <li><a href="#answer_1" class="level-3">Answer</a></li>
                <li><a href="#exercise-2-compare-algorithms" class="level-2">Exercise 2: Compare Algorithms</a></li>
                <li><a href="#answer_2" class="level-3">Answer</a></li>
                <li><a href="#comparison" class="level-3">Comparison</a></li>
                <li><a href="#when-to-use-token-bucket" class="level-3">When to Use Token Bucket</a></li>
                <li><a href="#when-to-use-sliding-window-log" class="level-3">When to Use Sliding Window Log</a></li>
                <li><a href="#hybrid-approach" class="level-3">Hybrid Approach</a></li>
                <li><a href="#answer_3" class="level-3">Answer</a></li>
                <li><a href="#exercise-3-distributed-rate-limiting" class="level-2">Exercise 3: Distributed Rate Limiting</a></li>
                <li><a href="#answer_4" class="level-3">Answer</a></li>
                <li><a href="#challenge" class="level-3">Challenge</a></li>
                <li><a href="#solution-options" class="level-3">Solution Options</a></li>
                <li><a href="#recommended-solution" class="level-3">Recommended Solution</a></li>
                <li><a href="#consistency-guarantees" class="level-3">Consistency Guarantees</a></li>
                <li><a href="#answer_5" class="level-3">Answer</a></li>
            </ul>
        </div>
    </aside>
    <main class="main-content container mx-auto px-4 sm:px-6 lg:px-8 py-12">
        <div class="content">
<h1 id="answer-key-rate-limiter-implementations">Answer Key: Rate Limiter Implementations</h1>
<p><a href="../../05-llD-patterns/rate-limiting.html">Back to Exercises</a></p>
<hr />
<h2 id="exercise-1-implement-token-bucket">Exercise 1: Implement Token Bucket</h2>
<p><strong>Question</strong>: Implement a token bucket rate limiter. What are the edge cases?</p>
<h3 id="answer">Answer</h3>
<p><strong>Goal</strong>: Implement token bucket rate limiter with edge case handling</p>
<h3 id="implementation">Implementation</h3>
<p><strong>Python Implementation</strong>:</p>
<pre><code class="language-python">import time
import threading

class TokenBucket:
    def __init__(self, capacity, rate):
        &quot;&quot;&quot;
        capacity: Maximum tokens (burst size)
        rate: Tokens added per second (sustained rate)
        &quot;&quot;&quot;
        self.capacity = capacity
        self.rate = rate
        self.tokens = capacity
        self.last_update = time.time()
        self.lock = threading.Lock()

    def allow_request(self, tokens_needed=1):
        &quot;&quot;&quot;
        Check if request is allowed.
        Returns True if allowed, False otherwise.
        &quot;&quot;&quot;
        with self.lock:
            # Add tokens based on time elapsed
            now = time.time()
            time_elapsed = now - self.last_update
            tokens_to_add = time_elapsed * self.rate
            self.tokens = min(self.capacity, self.tokens + tokens_to_add)
            self.last_update = now

            # Check if enough tokens
            if self.tokens &gt;= tokens_needed:
                self.tokens -= tokens_needed
                return True
            else:
                return False
</code></pre>
<h3 id="edge-cases">Edge Cases</h3>
<p><strong>1. Concurrent Access</strong></p>
<p><strong>Issue</strong>: Multiple threads accessing bucket simultaneously</p>
<p><strong>Solution</strong>: Use locks (threading.Lock) to ensure thread safety</p>
<p><strong>2. Clock Skew</strong></p>
<p><strong>Issue</strong>: System clock changes (NTP updates, time adjustments)</p>
<p><strong>Problem</strong>: Time calculations become incorrect</p>
<p><strong>Solution</strong>: 
- Use monotonic clock (<code>time.monotonic()</code>) instead of wall clock
- Or handle clock jumps gracefully</p>
<p><strong>3. First Request</strong></p>
<p><strong>Issue</strong>: First request after initialization</p>
<p><strong>Solution</strong>: Initialize <code>last_update</code> to current time, start with full tokens</p>
<p><strong>4. Long Idle Period</strong></p>
<p><strong>Issue</strong>: No requests for long time, tokens accumulate</p>
<p><strong>Problem</strong>: May allow burst larger than intended</p>
<p><strong>Solution</strong>: Already handled (tokens capped at capacity)</p>
<p><strong>5. Very High Rate</strong></p>
<p><strong>Issue</strong>: Rate higher than capacity</p>
<p><strong>Problem</strong>: Tokens added faster than capacity</p>
<p><strong>Solution</strong>: Already handled (tokens capped at capacity)</p>
<p><strong>6. Zero or Negative Values</strong></p>
<p><strong>Issue</strong>: Invalid capacity or rate values</p>
<p><strong>Solution</strong>: Validate inputs, raise errors for invalid values</p>
<p><strong>7. Precision Issues</strong></p>
<p><strong>Issue</strong>: Floating point precision in time calculations</p>
<p><strong>Problem</strong>: Small errors accumulate</p>
<p><strong>Solution</strong>: Use high-precision time, or use integer-based calculations</p>
<h3 id="improved-implementation">Improved Implementation</h3>
<pre><code class="language-python">import time
import threading

class TokenBucket:
    def __init__(self, capacity, rate):
        if capacity &lt;= 0 or rate &lt;= 0:
            raise ValueError(&quot;Capacity and rate must be positive&quot;)

        self.capacity = float(capacity)
        self.rate = float(rate)
        self.tokens = float(capacity)
        self.last_update = time.monotonic()  # Use monotonic clock
        self.lock = threading.Lock()

    def allow_request(self, tokens_needed=1):
        with self.lock:
            # Add tokens based on time elapsed
            now = time.monotonic()
            time_elapsed = now - self.last_update

            # Handle clock jumps (shouldn't happen with monotonic, but be safe)
            if time_elapsed &lt; 0:
                time_elapsed = 0

            tokens_to_add = time_elapsed * self.rate
            self.tokens = min(self.capacity, self.tokens + tokens_to_add)
            self.last_update = now

            # Check if enough tokens
            if self.tokens &gt;= tokens_needed:
                self.tokens -= tokens_needed
                return True
            else:
                return False

    def get_tokens_available(self):
        &quot;&quot;&quot;Get current number of tokens available&quot;&quot;&quot;
        with self.lock:
            now = time.monotonic()
            time_elapsed = now - self.last_update
            if time_elapsed &lt; 0:
                time_elapsed = 0
            tokens_to_add = time_elapsed * self.rate
            current_tokens = min(self.capacity, self.tokens + tokens_to_add)
            return current_tokens
</code></pre>
<h3 id="answer_1">Answer</h3>
<p><strong>Token Bucket Implementation</strong>:</p>
<p><strong>Key components</strong>:
- Capacity (burst size)
- Rate (tokens per second)
- Tokens (current count)
- Last update time
- Lock (for thread safety)</p>
<p><strong>Edge cases</strong>:
1. <strong>Concurrent access</strong>: Use locks for thread safety
2. <strong>Clock skew</strong>: Use monotonic clock
3. <strong>First request</strong>: Initialize last_update to current time
4. <strong>Long idle</strong>: Tokens capped at capacity
5. <strong>High rate</strong>: Tokens capped at capacity
6. <strong>Invalid inputs</strong>: Validate capacity and rate
7. <strong>Precision</strong>: Use float or high-precision calculations</p>
<p><strong>Key principles</strong>:
- <strong>Thread safety</strong>: Use locks
- <strong>Clock handling</strong>: Use monotonic clock
- <strong>Input validation</strong>: Validate inputs
- <strong>Precision</strong>: Handle floating point precision</p>
<hr />
<h2 id="exercise-2-compare-algorithms">Exercise 2: Compare Algorithms</h2>
<p><strong>Question</strong>: Compare token bucket vs sliding window log. When would you use each?</p>
<h3 id="answer_2">Answer</h3>
<p><strong>Goal</strong>: Understand tradeoffs between token bucket and sliding window log</p>
<h3 id="comparison">Comparison</h3>
<table>
<thead>
<tr>
<th>Aspect</th>
<th>Token Bucket</th>
<th>Sliding Window Log</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Accuracy</strong></td>
<td>Medium (approximate)</td>
<td>High (precise)</td>
</tr>
<tr>
<td><strong>Memory</strong></td>
<td>O(1)</td>
<td>O(n) where n = requests in window</td>
</tr>
<tr>
<td><strong>CPU</strong></td>
<td>O(1)</td>
<td>O(n) to clean old entries</td>
</tr>
<tr>
<td><strong>Burst Handling</strong></td>
<td>Yes (allows bursts)</td>
<td>No (strict limit)</td>
</tr>
<tr>
<td><strong>Complexity</strong></td>
<td>Simple</td>
<td>More complex</td>
</tr>
<tr>
<td><strong>Distributed</strong></td>
<td>Easy (Redis counters)</td>
<td>Hard (need to sync logs)</td>
</tr>
</tbody>
</table>
<h3 id="when-to-use-token-bucket">When to Use Token Bucket</h3>
<p><strong>Use token bucket when</strong>:
- <strong>Burst handling needed</strong>: Need to allow bursts up to capacity
- <strong>Memory constrained</strong>: Limited memory available
- <strong>High throughput</strong>: Need to handle many requests
- <strong>Simple implementation</strong>: Want simple, efficient solution
- <strong>Distributed</strong>: Need distributed rate limiting</p>
<p><strong>Examples</strong>:
- API rate limiting (allow bursts)
- Network traffic shaping
- Resource allocation</p>
<h3 id="when-to-use-sliding-window-log">When to Use Sliding Window Log</h3>
<p><strong>Use sliding window log when</strong>:
- <strong>Accuracy critical</strong>: Need precise limit enforcement
- <strong>Memory available</strong>: Have memory for request logs
- <strong>Low throughput</strong>: Fewer requests (memory manageable)
- <strong>Strict limits</strong>: Need strict limit (no bursts)
- <strong>Single server</strong>: Not distributed</p>
<p><strong>Examples</strong>:
- Payment processing (strict limits)
- Critical operations (precise control)
- Low-volume APIs</p>
<h3 id="hybrid-approach">Hybrid Approach</h3>
<p><strong>Best of both worlds</strong>:
- Use token bucket for high-volume, burst-tolerant scenarios
- Use sliding window log for low-volume, accuracy-critical scenarios
- Or use sliding window counter (compromise)</p>
<h3 id="answer_3">Answer</h3>
<p><strong>Token Bucket</strong>:
- <strong>Use when</strong>: Burst handling needed, memory constrained, high throughput, distributed
- <strong>Pros</strong>: Simple, efficient, allows bursts, low memory
- <strong>Cons</strong>: Less accurate, approximate</p>
<p><strong>Sliding Window Log</strong>:
- <strong>Use when</strong>: Accuracy critical, memory available, low throughput, strict limits
- <strong>Pros</strong>: Precise, accurate limit enforcement
- <strong>Cons</strong>: High memory, high CPU, complex, hard to distribute</p>
<p><strong>Recommendation</strong>:
- <strong>Most cases</strong>: Use token bucket (simpler, more efficient)
- <strong>Critical cases</strong>: Use sliding window log (more accurate)
- <strong>Compromise</strong>: Use sliding window counter (balance)</p>
<hr />
<h2 id="exercise-3-distributed-rate-limiting">Exercise 3: Distributed Rate Limiting</h2>
<p><strong>Question</strong>: Design a distributed rate limiter. How do you ensure consistency?</p>
<h3 id="answer_4">Answer</h3>
<p><strong>Goal</strong>: Rate limiting across multiple servers with consistency</p>
<h3 id="challenge">Challenge</h3>
<p><strong>Problem</strong>: Multiple servers need to share rate limit state</p>
<p><strong>Requirements</strong>:
- Consistent limits across servers
- Low latency
- High availability
- Accurate</p>
<h3 id="solution-options">Solution Options</h3>
<p><strong>1. Centralized Store (Redis)</strong></p>
<p><strong>Architecture</strong>:
- All servers check Redis for rate limits
- Redis stores counters/tokens
- Atomic operations ensure consistency</p>
<p><strong>Implementation</strong>:</p>
<pre><code class="language-python">import redis

class DistributedTokenBucket:
    def __init__(self, redis_client, key_prefix, capacity, rate):
        self.redis = redis_client
        self.key_prefix = key_prefix
        self.capacity = capacity
        self.rate = rate

    def allow_request(self, client_id, tokens_needed=1):
        key = f&quot;{self.key_prefix}:{client_id}&quot;
        now = time.time()

        # Use Redis Lua script for atomicity
        lua_script = &quot;&quot;&quot;
        local key = KEYS[1]
        local capacity = tonumber(ARGV[1])
        local rate = tonumber(ARGV[2])
        local tokens_needed = tonumber(ARGV[3])
        local now = tonumber(ARGV[4])

        local bucket = redis.call('HMGET', key, 'tokens', 'last_update')
        local tokens = tonumber(bucket[1]) or capacity
        local last_update = tonumber(bucket[2]) or now

        local time_elapsed = now - last_update
        local tokens_to_add = time_elapsed * rate
        tokens = math.min(capacity, tokens + tokens_to_add)

        if tokens &gt;= tokens_needed then
            tokens = tokens - tokens_needed
            redis.call('HMSET', key, 'tokens', tokens, 'last_update', now)
            redis.call('EXPIRE', key, 3600)  -- TTL
            return 1
        else
            redis.call('HMSET', key, 'tokens', tokens, 'last_update', now)
            redis.call('EXPIRE', key, 3600)
            return 0
        end
        &quot;&quot;&quot;

        result = self.redis.eval(lua_script, 1, key, 
                                 self.capacity, self.rate, 
                                 tokens_needed, now)
        return result == 1
</code></pre>
<p><strong>Pros</strong>:
- Consistent (single source of truth)
- Accurate
- Atomic operations</p>
<p><strong>Cons</strong>:
- Redis is single point of failure
- Network latency
- Redis capacity</p>
<p><strong>2. Distributed Counters</strong></p>
<p><strong>Architecture</strong>:
- Each server maintains local counter
- Periodically sync counters
- Use consensus algorithm</p>
<p><strong>Implementation</strong>:
- Use Raft or Paxos for consensus
- More complex, eventual consistency</p>
<p><strong>Pros</strong>:
- No single point of failure
- Lower latency (local checks)</p>
<p><strong>Cons</strong>:
- Less accurate (eventual consistency)
- More complex
- Higher overhead</p>
<p><strong>3. Client-Side Enforcement</strong></p>
<p><strong>Architecture</strong>:
- Client enforces rate limit
- Server validates
- Use tokens or quotas</p>
<p><strong>Pros</strong>:
- Reduces server load
- Lower latency</p>
<p><strong>Cons</strong>:
- Not secure (client can bypass)
- Less accurate</p>
<h3 id="recommended-solution">Recommended Solution</h3>
<p><strong>Use Centralized Store (Redis) with</strong>:
- <strong>Redis Cluster</strong>: For high availability
- <strong>Lua scripts</strong>: For atomicity
- <strong>TTL</strong>: For cleanup
- <strong>Connection pooling</strong>: For performance</p>
<h3 id="consistency-guarantees">Consistency Guarantees</h3>
<p><strong>Strong Consistency</strong>:
- Use Redis with Lua scripts (atomic operations)
- Single Redis instance or Redis Cluster with strong consistency</p>
<p><strong>Eventual Consistency</strong>:
- Use distributed counters
- Accept some inconsistency for better performance</p>
<h3 id="answer_5">Answer</h3>
<p><strong>Distributed Rate Limiter Design</strong>:</p>
<p><strong>Architecture</strong>: <strong>Centralized Store (Redis)</strong></p>
<p><strong>Components</strong>:
1. <strong>Redis</strong>: Stores rate limit state (counters/tokens)
2. <strong>Lua scripts</strong>: Atomic operations for consistency
3. <strong>Key structure</strong>: <code>rate_limit:{client_id}</code> or <code>rate_limit:{user_id}</code>
4. <strong>TTL</strong>: Expire keys after window (cleanup)</p>
<p><strong>Consistency</strong>:
- <strong>Atomic operations</strong>: Lua scripts ensure atomicity
- <strong>Single source of truth</strong>: Redis is authoritative
- <strong>Strong consistency</strong>: All servers see same state</p>
<p><strong>High Availability</strong>:
- <strong>Redis Cluster</strong>: Multiple Redis nodes
- <strong>Failover</strong>: Automatic failover
- <strong>Replication</strong>: Data replicated</p>
<p><strong>Performance</strong>:
- <strong>Connection pooling</strong>: Reuse connections
- <strong>Pipeline</strong>: Batch operations
- <strong>Local caching</strong>: Cache recent decisions (with TTL)</p>
<p><strong>Tradeoffs</strong>:
- <strong>Consistency vs Performance</strong>: Strong consistency has higher latency
- <strong>Accuracy vs Complexity</strong>: Centralized is simpler but has single point of failure</p>
<p><strong>Best practice</strong>: Use Redis Cluster with Lua scripts for strong consistency and high availability.</p>
        </div>
    </main>
    <footer class="bg-gray-800 text-white text-center p-6 mt-16">
        <p>&copy; 2025 Data Engineering Guides. An illustrative web application.</p>
    </footer>
    <script>
        mermaid.initialize({ startOnLoad: true, theme: 'default' });
        
        // Sidebar toggle functionality
        document.addEventListener('DOMContentLoaded', function() {
            const sidebar = document.getElementById('sidebar');
            const sidebarToggle = document.getElementById('sidebarToggle');
            const mainContent = document.querySelector('.main-content');
            
            // Toggle sidebar
            if (sidebarToggle) {
                sidebarToggle.addEventListener('click', function() {
                    sidebar.classList.toggle('expanded');
                });
            }
            
            // Close sidebar when clicking outside on mobile
            document.addEventListener('click', function(event) {
                if (window.innerWidth <= 1024) {
                    if (!sidebar.contains(event.target) && !sidebarToggle.contains(event.target)) {
                        sidebar.classList.remove('expanded');
                    }
                }
            });
            
            // Update active link on scroll
            const headings = document.querySelectorAll('.content h1, .content h2, .content h3, .content h4');
            const sidebarLinks = document.querySelectorAll('.sidebar-nav a');
            
            function updateActiveLink() {
                let current = '';
                headings.forEach(heading => {
                    const rect = heading.getBoundingClientRect();
                    if (rect.top <= 100) {
                        current = heading.id;
                    }
                });
                
                sidebarLinks.forEach(link => {
                    link.classList.remove('active');
                    if (link.getAttribute('href') === '#' + current) {
                        link.classList.add('active');
                    }
                });
            }
            
            window.addEventListener('scroll', updateActiveLink);
            updateActiveLink();
            
            // Smooth scroll for sidebar links
            sidebarLinks.forEach(link => {
                link.addEventListener('click', function(e) {
                    const href = this.getAttribute('href');
                    if (href.startsWith('#')) {
                        e.preventDefault();
                        const target = document.querySelector(href);
                        if (target) {
                            const headerOffset = 80;
                            const elementPosition = target.getBoundingClientRect().top;
                            const offsetPosition = elementPosition + window.pageYOffset - headerOffset;
                            
                            window.scrollTo({
                                top: offsetPosition,
                                behavior: 'smooth'
                            });
                            
                            // Close sidebar on mobile after click
                            if (window.innerWidth <= 1024) {
                                sidebar.classList.remove('expanded');
                            }
                        }
                    }
                });
            });
        });
    </script>
</body>
</html>
